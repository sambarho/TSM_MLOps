{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fed0821",
   "metadata": {},
   "source": [
    "Downloading the sentence comparison model from huggingface (only done once by Petar - it will be saved and accessable through Git from now on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f26069b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pemla\\anaconda3\\envs\\resume-matcher\\Lib\\site-packages\\huggingface_hub\\file_download.py:933: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.\n",
      "For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3221ddf79934579a7bf90af4c69f79d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 30 files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67d6522d95c34dcf8cc5a65fa27c59d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90ef6d365061484896144d3e16c8944b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3be85ab85e54fcaafd73b32dc5e8d5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd770008465f4eed9703623bb32b3aaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c80cd5393ec4416bac32d7c10ef7c40c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de54df939dd34fa190d76bd1a530badd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data_config.json:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db01399bd24a486f9da7fda48ae5f9f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/1.23k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4b8f6aa977c47db981ce4425514a993",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de71268ccd764b758439dfb1ed3b0d1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.onnx:   0%|          | 0.00/90.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eb26da4d15144f1a962a6090a558830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model_O2.onnx:   0%|          | 0.00/90.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7842e1ef5fb24fe0aac3d8d04a085618",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model_O1.onnx:   0%|          | 0.00/90.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d61540cc41e4a3f89ef89a78858991d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model_O3.onnx:   0%|          | 0.00/90.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac04a2fc6cc740ebaaa5a38babb5ea28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model_O4.onnx:   0%|          | 0.00/45.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6fd3715e9744c8a93c61468c32721a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model_qint8_arm64.onnx:   0%|          | 0.00/23.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b24de9873038432caa77a247cf2df0af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model_qint8_arm64.onnx:   0%|          | 0.00/23.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dae53c923e6d4944a968c856365de57e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model_qint8_arm64.onnx:   0%|          | 0.00/23.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c731a085b764257804205a94e5c5678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model_quint8_avx2.onnx:   0%|          | 0.00/23.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0dbb56663ac445ba81c5f6e07dd5db8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "openvino_model.bin:   0%|          | 0.00/90.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5716556353c84c059e94af0f0abbcb7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "openvino_model.xml:   0%|          | 0.00/211k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e34765fb91734c6082266ef3eb203ed6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "openvino_model_qint8_quantized.xml:   0%|          | 0.00/368k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ca261297bc34c4c803473502bf62ec3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "openvino_model_qint8_quantized.bin:   0%|          | 0.00/22.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da97e22fad1c4c3cb232ff4ecb683c03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99e4774424a94114b2fc5a41d433d14c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "rust_model.ot:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20fa769e643e4891bbea3ac0972a271b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25e68f24aaa143a2b60a1ac163b2cd04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32f28b691ce04ee28346aa2429b9ced3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tf_model.h5:   0%|          | 0.00/91.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e614ec4c5f84a4d83faff393b896a1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d13a8c7a88a247b080b994f6e5a0e516",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c3f68e912bc44c49b0cc76c4811b43c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train_script.py:   0%|          | 0.00/13.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6734bf3278be4b50987f6589e76f05ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Schule\\\\Master\\\\Semester 2\\\\TSM_MachLeData\\\\project\\\\TSM_MLOps\\\\resume_matcher\\\\notebooks\\\\models\\\\all-MiniLM-L6-v2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "# Download the model and store it in the models directory\n",
    "snapshot_download(\n",
    "    repo_id=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    local_dir=\"models/all-MiniLM-L6-v2\",\n",
    "    local_dir_use_symlinks=False  # This ensures full files are copied, not symlinked\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96330fd5",
   "metadata": {},
   "source": [
    "Load the model to use it - you run this cell before you want to use the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc515a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"../models/all-MiniLM-L6-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3748b690",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CYNTHIA DWAYNE\n",
      "Software Developer\n",
      "CONTACT WORK EXPERIENCE\n",
      "cynthia@beamjobs.com Software Developer\n",
      "(123) 456-7890\n",
      "QuickBooks\n",
      "Brooklyn, NY\n",
      "January 2017 - current / New York, NY\n",
      "LinkedIn\n",
      "¬∑ Worked on the payments team to save time and improve cash\n",
      "Github\n",
      "flow for over 50,000 through the development of modern,\n",
      "responsive customer experiences\n",
      "¬∑ Led the migration from AWS to GCP for the team to reduce\n",
      "CAREER OBJECTIVE\n",
      "cloud costs by $260,000 per year\n",
      "Throughout my 7-year-plus ¬∑ Worked closely with the product team to re-configure the\n",
      "career as a software developer, I processing of invoices, saving customers over 125,000 manual\n",
      "have focused on developing hours of work per month\n",
      "scalable and well-documented ¬∑ Mentored 3 junior front-end developers on the team on React,\n",
      "code. I enjoy working\n",
      "and documented best practices within the organization\n",
      "collaboratively but can also run\n",
      "with projects independently.\n",
      "Front-End Developer\n",
      "Excited about the prospect of\n",
      "joining a product-driven AMR\n",
      "company like Acme Corp.\n",
      "January 2014 - December 2016 / New York, NY\n",
      "¬∑ Contributed to the in-house UI library to create reusable\n",
      "components that saved 125+ hours of development per month\n",
      "EDUCATION\n",
      "¬∑ Created a web app MVP for a store delivery management\n",
      "Bachelor of Science platform with 200+ business customers to create, manage, and\n",
      "Computer Science monitor deliveries using React and Redux\n",
      "¬∑ Added features to meditation app with 5,000+ monthly users,\n",
      "University of Delaware\n",
      "enabling audio and video uploads using React and Redux\n",
      "August 2008 - May 2012\n",
      "¬∑ Improved customer conversion rate by 17% through A/B\n",
      "Newark, DE\n",
      "testing of different components and combinations,\n",
      "representing $500,000+ in incremental annual revenue\n",
      "SKILLS\n",
      "Help Desk Analyst\n",
      "Python (Django)\n",
      "Kelly\n",
      "SQL (PostgreSQL, MySQL)\n",
      "June 2012 - January 2014 / New York, NY\n",
      "Cloud (GCP, AWS)\n",
      "¬∑ Diagnosed technical issues for 30+ clients per day by phone,\n",
      "JavaScript (ES6, React, Redux,\n",
      "email, and chat, solving issues within 15 minutes on average\n",
      "Node.js)\n",
      "¬∑ Successfully reached solutions for 92% of computer errors, and\n",
      "Typescript\n",
      "escalated more complex tickets to higher tiers to assist clients\n",
      "HTML/ CSS\n",
      "as quickly as possible\n",
      "CI/CD\n",
      "¬∑ Created user accounts for 50+ clients per week, and assisted\n",
      "them with setting up and customizing their accounts\n",
      "¬∑ Created and updated documentation as needed concerning\n",
      "network, software, and hardware problems\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        return \"\\n\".join([page.extract_text() or \"\" for page in pdf.pages])\n",
    "\n",
    "# Load your own resume file here\n",
    "resume_path = \"../data/resumes/sample_resume.pdf\"\n",
    "resume_text = extract_text_from_pdf(resume_path)\n",
    "\n",
    "print(resume_text[:10000])  # Preview the first 1000 characters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cdc9b3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_description = \"\"\"Construction is a multi-trillion-dollar industry used by every human across the planet. It needs your help: we need to invent new software systems so construction becomes as efficient, quick, automated and green as possible. The team at Benetics (60+ years of engineering experience, 2 founding engineers from Google, and a CEO with a successful exit in tech.) is laser-focused on a vision of understanding each building‚Äôs DNA: How are people on-site communicating? How was the building constructed compared to what the plan said? How can we automate planning, implementation, logistics, and maintenance into a seamless process flow?\n",
    "Join the fastest-moving company in this space.\n",
    "\n",
    "Tasks\n",
    "\n",
    "Build reliable, performant, and scalable software solutions.\n",
    "Follow data-driven experimentation to iterate on features.\n",
    "Bring machine learning models for construction process flows.\n",
    "Work closely and collaborate with engineers, product managers, designers, and other team members.\n",
    "Share expertise, hold tech talks, contribute to design meetings, and enrich our engineering culture.\n",
    "Tackle greenfield algorithmic, scaling, and performance challenges.\n",
    "Code using primarily TypeScript and Python\n",
    "Requirements\n",
    "\n",
    "\\[required] 2+ years of software engineering experience\n",
    "\\[required] Master‚Äôs or bachelor‚Äôs degree (or equivalent) in computer science, mathematics, or related fields (ETH Zurich or equivalent)\n",
    "Your A-Game: top-notch software engineering, a curious mind looking to learn constantly, and an empathic style that wants to teach others.\n",
    "Benefits\n",
    "\n",
    "Experienced and powerful team; a start-up without the chaos.\n",
    "Quick pacing while paying attention to all the details: we build a delightful, bullet-proof product.\n",
    "Performance-driven compensation, including equity.\n",
    "A place to learn and develop yourself.\n",
    "A once-in-a-generation chance to reshape an industry of crucial importance for humanity and the planet.\n",
    "We are hiring the best people around the world and offer visa sponsorship.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e4945c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    # lowercase the text\n",
    "    text = text.lower()\n",
    "    #remove special characters \n",
    "    text = re.sub(r\"[\\n‚Ä¢\\-]+\", \" \", text)\n",
    "    # Remove extra spaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9eeef567",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_clean = clean_text(resume_text)\n",
    "job_clean = clean_text(job_description)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "603c34dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume Fit Score: 54.72/100\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers.util import cos_sim\n",
    "\n",
    "# encode texts to get their embeddings\n",
    "embeddings = model.encode([resume_text, job_description], convert_to_tensor=True)\n",
    "\n",
    "# cosine similarity score\n",
    "similarity = cos_sim(embeddings[0], embeddings[1]).item()\n",
    "print(f\"Resume Fit Score: {similarity * 100:.2f}/100\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da57d3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyword Overlap: 16.67%\n"
     ]
    }
   ],
   "source": [
    "# basic keyword overlap\n",
    "resume_words = set(clean_text(resume_text).split())\n",
    "job_words = set(clean_text(job_description).split())\n",
    "overlap = len(resume_words & job_words) / len(job_words)\n",
    "print(f\"Keyword Overlap: {overlap:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc5bcc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Your max_length is set to 450, but your input_length is only 326. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=163)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Summarized Job Description:\n",
      "  Position is limited 6 months, 80-100% full-time, all genders . Position is to drive the proof of concept of a digitalization use case for the procurement of airframe services . Must be fluent in English, German is a plus . Must have strong interest in aviation sector and strong interest for aviation sector . Must also have strong experience with MS Office products (Excel, Teams) and with Power Automate . Workload Specification: For this position, an 80 to 100% workload is preferred. Must be bilingual in English and fluent in German. Must work effectively with others and team-oriented person with strong analytical thinking. Must have good communication skills. Must experience with BI visualization tools (e.g. Tableau) Must have knowledge of database structures. Must also be proficient in Tableau. Need to be knowledgeable about Tableau and knowledge of Tableau‚Äôs ability to use Microsoft Office products. Needed to be comfortable in English. Must provide knowledge of data analysis experience, preferably SQL is an advantage. Must include knowledge of databases and strong understanding of database systems. Must engage in a strong work effectively and work effectively in a good work ethic. Must contribute with other analysts and be committed to a strong commitment to work effectively to succeed in a successful project. Must demonstrate knowledge of a successful outcome. Must meet requirements for a successful completion of a long-term commitment to a successful delivery of a short-interference. Must‚Äôt be a successful and successful\n",
      "üîç Summarized Resume:\n",
      "  This is a resume - summarizing in order to fit potential job descriptions . Worked on the payments team to save time and improve cash . Mentored 3 junior front-end developers on the team on React, code . Led migration from AWS to GCP for the team to reduce cloud costs by $260,000 per year . Enjoyed working with the product team to re-configure the company's product . Contributed to the in-house UI library to create reusable UI library that saved 125+ hours of development per month . Created user accounts for 50+ clients per week, and assisted with setting up and customizing their accounts . Diagnosed technical issues for 30+ clients by phone, and solved issues within 15 minutes on average by phone. Diagnosed . Issues for 30 more clients per day by phone by phone,. Diagnosed Technical issues for . phone, but solved issues for 92% of computer errors. Successfully reached solutions for 92%. Successfully found solutions for 90% of . computer errors, and . solved issues in 15 minutes . The company's helpdesk (Django) and . updated documentation as needed concerning network, software, hardware, and software, and hardware problems . I'm excited about the prospect of joining a product-driven AMR company like Acme Corp. The company‚Äôs expertise. The Company‚ÄôS helpdeskerkerkerkert ‚ÄòCriskerker‚Äô and ‚ÄòKerkerkerner‚Äô\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\")\n",
    "\n",
    "summary_job_desc = summarizer(\"This is a job description - summarizing in order to fit potential resumes:\" + job_description, max_length=450, min_length=300, do_sample=False)[0]['summary_text']\n",
    "print(\"Summarized Job Description:\\n\", summary_job_desc)\n",
    "\n",
    "summary_resume_text = summarizer(\"This is a resume - summarizing in order to fit potential job descriptions:\" + resume_text, max_length=450, min_length=300, do_sample=False)[0]['summary_text']\n",
    "print(\"Summarized Resume:\\n\", summary_resume_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db367c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarized Resume Fit Score: 35.93/100\n"
     ]
    }
   ],
   "source": [
    "embeddings = model.encode([summary_resume_text, summary_job_desc], convert_to_tensor=True)\n",
    "\n",
    "# cosine similarity score\n",
    "similarity = cos_sim(embeddings[0], embeddings[1]).item()\n",
    "print(f\"Summarized Resume Fit Score: {similarity * 100:.2f}/100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be04143d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume Fit Score (MS MARCO): 41.57/100\n"
     ]
    }
   ],
   "source": [
    "model2 = SentenceTransformer(\"sentence-transformers/msmarco-distilbert-base-v4\") #maybe more task specific\n",
    "embeddings2 = model2.encode([resume_clean, job_clean], convert_to_tensor=True)\n",
    "similarity2 = cos_sim(embeddings2[0], embeddings2[1]).item()\n",
    "print(f\"Resume Fit Score (MS MARCO): {similarity2 * 100:.2f}/100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36880ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume Fit Score (MS MARCO): 41.57/100\n"
     ]
    }
   ],
   "source": [
    "print(f\"Resume Fit Score (MS MARCO): {similarity2 * 100:.2f}/100\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daba68c2",
   "metadata": {},
   "source": [
    "Another approach: creating objects out of both texts and comparing them \"manually\" using ollama. does not work yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79438b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import Client\n",
    "client = Client()\n",
    "response = client.chat(model='tinyllama', messages=[\n",
    "    {\"role\": \"user\", \"content\": \"Extract skills and experience from this resume: <your text>\"}\n",
    "])\n",
    "print(response['message']['content'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78cec435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ollama in c:\\users\\pemla\\anaconda3\\envs\\resume-matcher\\lib\\site-packages (0.4.7)\n",
      "Requirement already satisfied: httpx<0.29,>=0.27 in c:\\users\\pemla\\anaconda3\\envs\\resume-matcher\\lib\\site-packages (from ollama) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in c:\\users\\pemla\\anaconda3\\envs\\resume-matcher\\lib\\site-packages (from ollama) (2.11.3)\n",
      "Requirement already satisfied: anyio in c:\\users\\pemla\\anaconda3\\envs\\resume-matcher\\lib\\site-packages (from httpx<0.29,>=0.27->ollama) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\pemla\\anaconda3\\envs\\resume-matcher\\lib\\site-packages (from httpx<0.29,>=0.27->ollama) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\pemla\\anaconda3\\envs\\resume-matcher\\lib\\site-packages (from httpx<0.29,>=0.27->ollama) (1.0.8)\n",
      "Requirement already satisfied: idna in c:\\users\\pemla\\anaconda3\\envs\\resume-matcher\\lib\\site-packages (from httpx<0.29,>=0.27->ollama) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\pemla\\anaconda3\\envs\\resume-matcher\\lib\\site-packages (from httpcore==1.*->httpx<0.29,>=0.27->ollama) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\pemla\\anaconda3\\envs\\resume-matcher\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\pemla\\anaconda3\\envs\\resume-matcher\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (2.33.1)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\pemla\\anaconda3\\envs\\resume-matcher\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (4.13.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\pemla\\anaconda3\\envs\\resume-matcher\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (0.4.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\pemla\\anaconda3\\envs\\resume-matcher\\lib\\site-packages (from anyio->httpx<0.29,>=0.27->ollama) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ollama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8482f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_resume_info(resume_text: str, model: str = 'mistral') -> dict:\n",
    "    from ollama import Client\n",
    "    client = Client()\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Extract the following fields from the resume below and return them as a valid JSON object:\n",
    "\n",
    "- name\n",
    "- years_of_experience\n",
    "- skills\n",
    "- past_job_titles\n",
    "- education\n",
    "- soft_skills\n",
    "\n",
    "Example output:\n",
    "{{\n",
    "  \"name\": \"Emma Liu\",\n",
    "  \"years_of_experience\": 3,\n",
    "  \"skills\": [\"Go\", \"Kubernetes\", \"PostgreSQL\"],\n",
    "  \"past_job_titles\": [\"Platform Engineer\", \"Backend Developer\"],\n",
    "  \"education\": \"MSc in Software Engineering\",\n",
    "  \"soft_skills\": [\"teamplayer\", \"problem solver\"]\n",
    "}}\n",
    "\n",
    "Resume:\n",
    "{resume_text}\n",
    "\n",
    "Respond only with valid JSON. Do not include any extra text or explanation.\n",
    "\"\"\"\n",
    "\n",
    "    response = client.chat(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "    return response['message']['content']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ccd40755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {\n",
      "    \"name\": \"Cynthia Dwayne\",\n",
      "    \"years_of_experience\": 5,\n",
      "    \"skills\": [\"Go\", \"Kubernetes\", \"PostgreSQL\", \"Python (Django)\", \"JavaScript (ES6, React, Redux)\", \"Node.js\", \"TypeScript\", \"HTML/CSS\", \"CI/CD\"],\n",
      "    \"past_job_titles\": [\"Software Developer\", \"Help Desk Analyst\"],\n",
      "    \"education\": \"BSc in Computer Science, University of Delaware\",\n",
      "    \"soft_skills\": [\"teamplayer\", \"problem solver\", \"mentor\"]\n",
      "  }\n"
     ]
    }
   ],
   "source": [
    "json_output = extract_resume_info(resume_clean)\n",
    "print(json_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd40f74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_job_description_info(jd_text: str, model: str = 'mistral') -> dict:\n",
    "    from ollama import Client\n",
    "    client = Client()\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Extract the following fields from the job description and return them as a valid JSON object:\n",
    "\n",
    "- title\n",
    "- required_experience\n",
    "- required_skills\n",
    "- preferred_skills\n",
    "- education\n",
    "- soft_skills\n",
    "\n",
    "Example output:\n",
    "{{\n",
    "  \"title\": \"Backend Engineer\",\n",
    "  \"required_experience\": 2,\n",
    "  \"required_skills\": [\"Python\", \"AWS\", \"PostgreSQL\"],\n",
    "  \"preferred_skills\": [\"Kubernetes\", \"Docker\"],\n",
    "  \"education\": \"Bachelor's in Computer Science\",\n",
    "  \"soft_skills\": [\"communication\", \"problem-solving\"]\n",
    "}}\n",
    "\n",
    "Job Description:\n",
    "{jd_text}\n",
    "\n",
    "Respond only with valid JSON. Do not include any additional explanation or formatting.\n",
    "\"\"\"\n",
    "\n",
    "    response = client.chat(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "    return response['message']['content']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c6bb6590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {\n",
      "      \"title\": \"Software Engineer\",\n",
      "      \"required_experience\": 2,\n",
      "      \"required_skills\": [\"Typescript\", \"Python\"],\n",
      "      \"preferred_skills\": [],\n",
      "      \"education\": \"Bachelor's or Master's in Computer Science, Mathematics, or related fields\",\n",
      "      \"soft_skills\": [\"curious mind\", \"teaching style\"]\n",
      "   }\n"
     ]
    }
   ],
   "source": [
    "json_output_job = extract_job_description_info(job_clean)\n",
    "print(json_output_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed4b71a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_data = extract_resume_info(resume_clean)\n",
    "job_data = extract_job_description_info(job_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d36b145d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Resume matches 0.00% of required job skills.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "resume = json.loads(resume_data)\n",
    "job = json.loads(job_data)\n",
    "\n",
    "# Compare skills\n",
    "common_skills = set(resume[\"skills\"]).intersection(job[\"required_skills\"])\n",
    "match_score = len(common_skills) / len(job[\"required_skills\"]) * 100\n",
    "\n",
    "print(f\"üîç Resume matches {match_score:.2f}% of required job skills.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b9247797",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('models/all-MiniLM-L6-v2')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "20f177fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import util\n",
    "\n",
    "def compare_resume_and_job(resume: dict, job: dict, model, explain: bool = False) -> float:\n",
    "    def sim(a, b):\n",
    "        return util.cos_sim(model.encode(a, convert_to_tensor=True),\n",
    "                            model.encode(b, convert_to_tensor=True)).item()\n",
    "\n",
    "    def sim_list(list1, list2, threshold=0.7):\n",
    "        matches = []\n",
    "        for item1 in list1:\n",
    "            for item2 in list2:\n",
    "                if sim(item1, item2) >= threshold:\n",
    "                    matches.append((item1, item2))\n",
    "        return matches\n",
    "\n",
    "    # --- 1. Skills ---\n",
    "    resume_skills = resume.get(\"skills\", [])\n",
    "    required_skills = job.get(\"required_skills\", [])\n",
    "    preferred_skills = job.get(\"preferred_skills\", [])\n",
    "\n",
    "    required_matches = sim_list(resume_skills, required_skills)\n",
    "    preferred_matches = sim_list(resume_skills, preferred_skills)\n",
    "\n",
    "    required_score = len(required_matches) / max(1, len(required_skills))\n",
    "    preferred_score = len(preferred_matches) / max(1, len(preferred_skills))\n",
    "    skill_score = (required_score * 0.8) + (preferred_score * 0.2)\n",
    "\n",
    "    # --- 2. Experience (rule-based) ---\n",
    "    resume_exp = resume.get(\"years_of_experience\", 0)\n",
    "    job_exp = job.get(\"required_experience\", 0)\n",
    "\n",
    "    if isinstance(resume_exp, str):\n",
    "        resume_exp = int(''.join(filter(str.isdigit, resume_exp)) or 0)\n",
    "\n",
    "    exp_score = 1.0 if resume_exp >= job_exp else 0.5 if resume_exp >= job_exp * 0.75 else 0.0\n",
    "\n",
    "    # --- 3. Job Title (semantic similarity) ---\n",
    "    resume_titles = resume.get(\"past_job_titles\", [])\n",
    "    job_title = job.get(\"title\", \"\")\n",
    "    title_score = 0.0\n",
    "\n",
    "    for rt in resume_titles:\n",
    "        if sim(rt, job_title) > 0.75:\n",
    "            title_score = 1.0\n",
    "            break\n",
    "\n",
    "    # --- 4. Education (semantic match) ---\n",
    "    import re\n",
    "\n",
    "    def simplify_education(text):\n",
    "        text = text.lower()\n",
    "        text = re.sub(r\"bachelor(?:'s)?|bsc\", \"bachelor\", text)\n",
    "        text = re.sub(r\"master(?:'s)?|msc\", \"master\", text)\n",
    "        text = re.sub(r\"(in|of)\", \"\", text)\n",
    "        text = re.sub(r\"[,\\.]\", \"\", text)\n",
    "        # remove university names, keep degree + subject\n",
    "        keywords = [\"bachelor\", \"master\", \"computer science\", \"mathematics\", \"data science\", \"engineering\"]\n",
    "        return ' '.join([kw for kw in keywords if kw in text])\n",
    "\n",
    "    resume_edu_clean = simplify_education(resume.get(\"education\", \"\"))\n",
    "    job_edu_clean = simplify_education(job.get(\"education\", \"\"))\n",
    "\n",
    "    edu_score = sim(resume_edu_clean, job_edu_clean) if resume_edu_clean and job_edu_clean else 0.0\n",
    "    edu_score = 1.0 if edu_score > 0.7 else 0.0\n",
    "\n",
    "    # --- 5. Final Weighted Score ---\n",
    "    final_score = (\n",
    "        skill_score * 0.5 +\n",
    "        exp_score * 0.2 +\n",
    "        title_score * 0.2 +\n",
    "        edu_score * 0.1\n",
    "    )\n",
    "\n",
    "    percent_score = round(final_score * 100, 2)\n",
    "\n",
    "    if explain:\n",
    "        print(\"üìä Match Breakdown:\")\n",
    "        print(f\"‚úîÔ∏è Required skills matched: {[m[1] for m in required_matches]}\")\n",
    "        print(f\"‚ûï Preferred skills matched: {[m[1] for m in preferred_matches]}\")\n",
    "        print(f\"üõ†Ô∏è Skill score: {round(skill_score * 100, 2)}%\")\n",
    "        print(f\"üìà Experience score: {round(exp_score * 100, 2)}%\")\n",
    "        print(f\"üéØ Title score: {round(title_score * 100, 2)}%\")\n",
    "        print(f\"üéì Education score: {round(edu_score * 100, 2)}%\")\n",
    "\n",
    "    return percent_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "90898391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Match Breakdown:\n",
      "‚úîÔ∏è Required skills matched: ['Typescript']\n",
      "‚ûï Preferred skills matched: []\n",
      "üõ†Ô∏è Skill score: 40.0%\n",
      "üìà Experience score: 100.0%\n",
      "üéØ Title score: 100.0%\n",
      "üéì Education score: 100.0%\n",
      "\n",
      "üîç Final Resume Fit Score: 70.0%\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "resume_raw = extract_resume_info(resume_clean)\n",
    "job_raw = extract_job_description_info(job_clean)\n",
    "\n",
    "resume_dict = json.loads(resume_raw)\n",
    "job_dict = json.loads(job_raw)\n",
    "\n",
    "\n",
    "model = SentenceTransformer('models/all-MiniLM-L6-v2')  # or just use HuggingFace name\n",
    "score = compare_resume_and_job(resume_dict, job_dict, model, True)\n",
    "\n",
    "print(f\"\\nüîç Final Resume Fit Score: {score}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "resume-matcher",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
